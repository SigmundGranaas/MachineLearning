{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "char_encodings = [\n",
    "    [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # ' '\n",
    "    [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'h'\n",
    "    [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'a'\n",
    "    [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],  # 't'\n",
    "    [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],  # 'r'\n",
    "    [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],  # 'c'\n",
    "    [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],  # 'f'\n",
    "    [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],  # 'l'\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],  # 'm'\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],  # 'p'\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],  # 's'\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],  # 'o'\n",
    "    [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]   # 'n'\n",
    "]\n",
    "char_encoding_size = len(char_encodings)\n",
    "\n",
    "index_to_char = [' ', 'h', 'a', 't', 'r', 'c', 'f', 'l', 'm', 'p', 's', 'o', 'n']\n",
    "\n",
    "hat = [[char_encodings[1]], [char_encodings[2]], [char_encodings[3]], [char_encodings[0]]]\n",
    "rat = [[char_encodings[4]], [char_encodings[2]], [char_encodings[3]], [char_encodings[0]]]\n",
    "cat = [[char_encodings[5]], [char_encodings[2]], [char_encodings[3]], [char_encodings[0]]]\n",
    "flat = [[char_encodings[6]], [char_encodings[7]], [char_encodings[2]], [char_encodings[3]]]\n",
    "matt = [[char_encodings[8]], [char_encodings[2]], [char_encodings[3]], [char_encodings[3]]]\n",
    "cap =  [[char_encodings[5]], [char_encodings[2]], [char_encodings[9]], [char_encodings[0]]]\n",
    "son =  [[char_encodings[10]], [char_encodings[11]], [char_encodings[12]], [char_encodings[0]]]\n",
    "\n",
    "hat_y = [char_encodings[0], char_encodings[0], char_encodings[0], char_encodings[0]]\n",
    "rat_y = [char_encodings[1], char_encodings[1], char_encodings[1], char_encodings[1]]\n",
    "cat_y = [char_encodings[2], char_encodings[2], char_encodings[2], char_encodings[2]]\n",
    "flat_y = [char_encodings[3], char_encodings[3], char_encodings[3], char_encodings[3]]\n",
    "matt_y = [char_encodings[4], char_encodings[4], char_encodings[4], char_encodings[4]]\n",
    "cap_y =  [char_encodings[5], char_encodings[5], char_encodings[5], char_encodings[5]]\n",
    "son_y =  [char_encodings[6], char_encodings[6], char_encodings[6], char_encodings[6]]\n",
    "\n",
    "emojis = {\n",
    "        'hat': '\\U0001F3A9',\n",
    "        'cat': '\\U0001F408',\n",
    "        'rat': '\\U0001F400',\n",
    "        'flat': '\\U0001F3E2',\n",
    "        'matt': '\\U0001F468',\n",
    "        'cap': '\\U0001F9E2',\n",
    "        'son': '\\U0001F466'\n",
    "    }\n",
    "\n",
    "index_to_emoji = [emojis['hat'], emojis['rat'], emojis['cat'], emojis['flat'], emojis['matt'], emojis['cap'], emojis['son']]\n",
    "\n",
    "emoji_encoding = [\n",
    "    [1., 0., 0., 0., 0., 0., 0.],  # 'hat'\n",
    "    [0., 1., 0., 0., 0., 0., 0.], # 'cat'\n",
    "    [0., 0., 1., 0., 0., 0., 0.], # 'rat'\n",
    "    [0., 0., 0., 1., 0., 0., 0.], # 'flat'\n",
    "    [0., 0., 0., 0., 1., 0., 0.],  # 'matt'\n",
    "    [0., 0., 0., 0., 0., 1., 0.],  # 'cap'\n",
    "    [0., 0., 0., 0., 0., 0., 1.]  # 'son'\n",
    "]\n",
    "emoji_encoding_size = len(emoji_encoding)\n",
    "\n",
    "x_train = torch.tensor([hat,\n",
    "                        rat,\n",
    "                        cat,\n",
    "                        flat,\n",
    "                        matt,\n",
    "                        cap,\n",
    "                        son])  # ' All the words '\n",
    "y_train = torch.tensor([hat_y,\n",
    "                        rat_y,\n",
    "                        cat_y,\n",
    "                        flat_y,\n",
    "                        matt_y,\n",
    "                        cap_y,\n",
    "                        son_y])  # ' All the words'\n",
    "\n",
    "test_words_list = [\"rt\", \"rats\", \"sn\", \"at\", \"cat\", \"hats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LongShortTermMemoryModel(nn.Module):\n",
    "    def __init__(self, encoding_size, label_size):\n",
    "        super(LongShortTermMemoryModel, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(char_encoding_size, 128)  # 128 is the state size\n",
    "        self.dense = nn.Linear(128, emoji_encoding_size)  # 128 is the state size\n",
    "\n",
    "    def reset(self, batch_size = 1):  # Reset states prior to new input sequence\n",
    "        zero_state = torch.zeros(1, batch_size, 128)  # Shape: (number of layers, batch size, state size)\n",
    "        self.hidden_state = zero_state\n",
    "        self.cell_state = zero_state\n",
    "\n",
    "    def logits(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        out, (self.hidden_state, self.cell_state) = self.lstm(x, (self.hidden_state, self.cell_state))\n",
    "        return self.dense(out.reshape(-1, 128))\n",
    "\n",
    "    def f(self, x):  # x shape: (sequence length, batch size, encoding size)\n",
    "        return torch.softmax(self.logits(x), dim=1)\n",
    "\n",
    "    def loss(self, x, y):  # x shape: (sequence length, batch size, encoding size), y shape: (sequence length, encoding size)\n",
    "        return nn.functional.cross_entropy(self.logits(x), y.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "word: rt prediction: üé©\n",
      "word: rats prediction: üé©\n",
      "word: sn prediction: üé©\n",
      "word: at prediction: üé©\n",
      "word: cat prediction: üé©\n",
      "word: hats prediction: üé©\n",
      "\n",
      "\n",
      "Epoch: 100\n",
      "word: rt prediction: üêÄ\n",
      "word: rats prediction: üêÄ\n",
      "word: sn prediction: üë¶\n",
      "word: at prediction: üë®\n",
      "word: cat prediction: üêà\n",
      "word: hats prediction: üé©\n",
      "\n",
      "\n",
      "Epoch: 200\n",
      "word: rt prediction: üêÄ\n",
      "word: rats prediction: üêÄ\n",
      "word: sn prediction: üë¶\n",
      "word: at prediction: üêÄ\n",
      "word: cat prediction: üêà\n",
      "word: hats prediction: üé©\n",
      "\n",
      "\n",
      "Epoch: 300\n",
      "word: rt prediction: üêÄ\n",
      "word: rats prediction: üêÄ\n",
      "word: sn prediction: üë¶\n",
      "word: at prediction: üé©\n",
      "word: cat prediction: üêà\n",
      "word: hats prediction: üé©\n",
      "\n",
      "\n",
      "Epoch: 400\n",
      "word: rt prediction: üêÄ\n",
      "word: rats prediction: üêÄ\n",
      "word: sn prediction: üë¶\n",
      "word: at prediction: üêÄ\n",
      "word: cat prediction: üêà\n",
      "word: hats prediction: üé©\n",
      "\n",
      "\n",
      "Epoch: 500\n",
      "word: rt prediction: üêÄ\n",
      "word: rats prediction: üêÄ\n",
      "word: sn prediction: üë¶\n",
      "word: at prediction: üêÄ\n",
      "word: cat prediction: üêà\n",
      "word: hats prediction: üé©\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LongShortTermMemoryModel(char_encoding_size, emoji_encoding_size)\n",
    "\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), 0.001)\n",
    "\n",
    "\n",
    "def test_words(word_list):\n",
    "    for word in word_list:\n",
    "        model.reset()\n",
    "        for letter in range(len(word)):\n",
    "            index = index_to_char.index(word[letter])\n",
    "            emoji_index = model.f(torch.tensor([[char_encodings[index]]]))\n",
    "            if letter == len(word) -1:\n",
    "                print(\"word: %s prediction: %s\" %(word, index_to_emoji[emoji_index.argmax(1)]))\n",
    "\n",
    "\n",
    "for epoch in range(501):\n",
    "    for i in range(7):\n",
    "        model.reset()\n",
    "        loss = model.loss(x_train[i], y_train[i])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: %s\" % epoch)\n",
    "        test_words(test_words_list)\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}